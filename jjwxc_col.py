#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
=================================================================
                æ™‹æ±Ÿæ–‡å­¦åŸä½œå“å¤‡ä»½å·¥å…· v5.0
=================================================================
åŠŸèƒ½è¯´æ˜:
- é€šè¿‡ä½œè€…åå°æ‰¹é‡å¤‡ä»½ä½œå“åˆ°DOCXæ ¼å¼
- æ”¯æŒå…è´¹ç« èŠ‚å’ŒVIPç« èŠ‚çš„å†…å®¹è·å–  
- è‡ªåŠ¨ä¿ç•™åŸæ–‡æ ¼å¼å’Œä½œè€…æœ‰è¯è¯´
- å®æ—¶ä¿å­˜ï¼Œè¾¹ä¸‹è½½è¾¹ç”Ÿæˆæ–‡æ¡£

æŠ€æœ¯ç‰¹æ€§:
- Cookieè®¤è¯ï¼šæ”¯æŒå¤æ‚Cookieæ ¼å¼è§£æ
- æ ¼å¼ä¿ç•™ï¼šå®Œæ•´ä¿æŒæ¢è¡Œç¬¦å’Œç©ºè¡Œ
- æ™ºèƒ½é‡è¯•ï¼šç½‘ç»œå¼‚å¸¸è‡ªåŠ¨é‡è¯•æœºåˆ¶

ä½¿ç”¨å‰æ:
1. éœ€è¦æ™‹æ±Ÿä½œè€…è´¦å·çš„ç™»å½•Cookie
2. åœ¨my_cookie.txtæ–‡ä»¶ä¸­ç²˜è´´å®Œæ•´Cookieå­—ç¬¦ä¸²
3. ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®š

=================================================================
"""

import os
import time
import random
import requests
from bs4 import BeautifulSoup
from docx import Document
from docx.shared import Pt, RGBColor
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT
import re
import json
from datetime import datetime
import urllib.parse

# ========================= å…¨å±€é…ç½® =========================
COOKIE_FILE = "my_cookie.txt"  # Cookieæ–‡ä»¶è·¯å¾„

class JJWXCBackupTool:
    """
    æ™‹æ±Ÿæ–‡å­¦åŸä½œå“å¤‡ä»½å·¥å…·ä¸»ç±»
    
    ä¸»è¦åŠŸèƒ½ï¼š
    1. Cookieè®¤è¯å’Œä¼šè¯ç®¡ç†
    2. ä½œå“åˆ—è¡¨è·å–å’Œè§£æ
    3. ç« èŠ‚å†…å®¹æŠ“å–ï¼ˆå…è´¹+VIPï¼‰
    4. DOCXæ–‡æ¡£ç”Ÿæˆå’Œæ ¼å¼åŒ–
    
    ä½¿ç”¨æµç¨‹ï¼š
    init() -> check_login() -> get_novel_list() -> select_novels() -> backup_novels()
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ–å¤‡ä»½å·¥å…·
        
        åŠŸèƒ½ï¼š
        - åˆ›å»ºè¾“å‡ºç›®å½•ç»“æ„ (backup/YYYYMMDD_HHMMSS/)
        - åˆå§‹åŒ–HTTPä¼šè¯å’Œè¯·æ±‚å¤´
        - åŠ è½½Cookieæ–‡ä»¶å¹¶è§£æè®¤è¯ä¿¡æ¯
        - é…ç½®ç½‘ç»œé‡è¯•ç­–ç•¥
        """
        # åˆ›å»ºè¾“å‡ºç›®å½• - ä½¿ç”¨timestampç¡®ä¿å”¯ä¸€æ€§
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.output_dir = os.path.join("backup", timestamp)
        os.makedirs(self.output_dir, exist_ok=True)
        print(f"è¾“å‡ºç›®å½•: {self.output_dir}")
        
        # è®¾ç½®HTTPä¼šè¯ - ä¿æŒCookieå’Œè¿æ¥å¤ç”¨
        self.session = requests.Session()
        self.headers = self.get_default_headers()
        
        # åˆå§‹åŒ–ä½œè€…åå°URL
        self.author_backend_url = None
        
        # åŠ è½½å¹¶è§£æCookieæ–‡ä»¶
        cookie_count = self.load_cookie()
        print(f"å·²è®¾ç½® {cookie_count} ä¸ªCookieå‚æ•°")
        
        # è®¾ç½®è¯·æ±‚é‡è¯•ç­–ç•¥ - åº”å¯¹ç½‘ç»œæ³¢åŠ¨
        self.session.mount('https://', requests.adapters.HTTPAdapter(
            max_retries=3,
            pool_connections=10,
            pool_maxsize=20
        ))

    def get_default_headers(self):
        """
        è·å–é»˜è®¤HTTPè¯·æ±‚å¤´
        
        è¿”å›ï¼š
            dict: åŒ…å«User-Agentã€Acceptç­‰æ ‡å‡†æµè§ˆå™¨è¯·æ±‚å¤´çš„å­—å…¸
            
        ç”¨é€”ï¼š
            æ¨¡æ‹ŸçœŸå®æµè§ˆå™¨è®¿é—®ï¼Œé¿å…è¢«ç½‘ç«™åçˆ¬è™«ç­–ç•¥æ‹¦æˆª
        """
        return {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Connection': 'keep-alive',
            'Referer': 'https://www.jjwxc.net/',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache'
        }
    
    def decode_unicode_escape(self, s):
        """
        è§£ç Unicodeè½¬ä¹‰åºåˆ—
        
        å‚æ•°ï¼š
            s (str): åŒ…å«%uXXXXæ ¼å¼Unicodeè½¬ä¹‰çš„å­—ç¬¦ä¸²
            
        è¿”å›ï¼š
            str: è§£ç åçš„å­—ç¬¦ä¸²
            
        è¯´æ˜ï¼š
            æ™‹æ±ŸCookieä¸­å¯èƒ½åŒ…å«%uæ ¼å¼çš„Unicodeè½¬ä¹‰å­—ç¬¦
            éœ€è¦ç‰¹æ®Šå¤„ç†æ‰èƒ½æ­£ç¡®è§£æä¸­æ–‡å­—ç¬¦
        """
        def replace_unicode(match):
            return chr(int(match.group(1), 16))
        return re.sub(r'%u([0-9a-fA-F]{4})', replace_unicode, s)
    
    def load_cookie(self):
        """
        ä»æ–‡ä»¶åŠ è½½å¹¶è§£æCookie
        
        è¿”å›ï¼š
            int: æˆåŠŸè§£æçš„Cookieæ•°é‡
            
        åŠŸèƒ½ï¼š
        1. è¯»å–my_cookie.txtæ–‡ä»¶å†…å®¹
        2. å¤„ç†Unicodeè½¬ä¹‰åºåˆ—(%uXXXX)
        3. æ™ºèƒ½è§£æå¤æ‚Cookieæ ¼å¼ï¼ˆåŒ…æ‹¬JSONå€¼ï¼‰
        4. è®¾ç½®åˆ°HTTPä¼šè¯ä¸­
        
        Cookieæ ¼å¼æ”¯æŒï¼š
        - æ ‡å‡†é”®å€¼å¯¹: key=value; key2=value2
        - JSONå€¼: key={"json":"value"}  
        - URLç¼–ç å€¼: key=%E4%B8%AD%E6%96%87
        - Unicodeè½¬ä¹‰: key=%u4E2D%u6587
        
        é”™è¯¯å¤„ç†ï¼š
        - æ–‡ä»¶ä¸å­˜åœ¨ï¼šè¿”å›0
        - è§£æå¤±è´¥ï¼šè·³è¿‡è¯¥Cookieå¹¶ç»§ç»­
        - JSONéªŒè¯ï¼šç¡®ä¿JSONæ ¼å¼Cookieçš„æœ‰æ•ˆæ€§
        """
        cookie_count = 0
        if os.path.exists(COOKIE_FILE):
            try:
                with open(COOKIE_FILE, 'r', encoding='utf-8') as f:
                    # è¯»å–åŸå§‹Cookieå†…å®¹
                    raw_cookie = f.read().strip()
                    print(f"åŸå§‹Cookieå†…å®¹: {raw_cookie[:100]}...")
                    
                    # ç¬¬ä¸€æ­¥ï¼šå¤„ç†Unicodeè½¬ä¹‰åºåˆ— (%uXXXX)
                    decoded_cookie = self.decode_unicode_escape(raw_cookie)
                    
                    # ç¬¬äºŒæ­¥ï¼šæ™ºèƒ½Cookieè§£æ - å¤„ç†åŒ…å«JSONçš„å¤æ‚Cookie
                    cookies_dict = {}
                    current_pos = 0
                    
                    while current_pos < len(decoded_cookie):
                        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªç­‰å·
                        eq_pos = decoded_cookie.find('=', current_pos)
                        if eq_pos == -1:
                            break
                            
                        # æå–é”®åï¼ˆå»æ‰å‰é¢çš„åˆ†å·å’Œç©ºæ ¼ï¼‰
                        key_start = current_pos
                        if decoded_cookie[current_pos:current_pos+1] == ';':
                            key_start += 1
                        key = decoded_cookie[key_start:eq_pos].strip()
                        
                        # æ‰¾å€¼çš„éƒ¨åˆ†
                        value_start = eq_pos + 1
                        
                        # å¦‚æœå€¼ä»¥ %7B æˆ– { å¼€å¤´ï¼Œå¯èƒ½æ˜¯JSONï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
                        if (decoded_cookie[value_start:value_start+3] == '%7B' or 
                            decoded_cookie[value_start:value_start+1] == '{'):
                            # JSONå€¼ï¼šæ‰¾åˆ°åŒ¹é…çš„ç»“æŸä½ç½®
                            brace_count = 0
                            value_end = value_start
                            in_string = False
                            escape_next = False
                            
                            for i in range(value_start, len(decoded_cookie)):
                                char = decoded_cookie[i]
                                
                                if escape_next:
                                    escape_next = False
                                    continue
                                    
                                if char == '\\':
                                    escape_next = True
                                    continue
                                    
                                if char == '"' and not escape_next:
                                    in_string = not in_string
                                    continue
                                    
                                if not in_string:
                                    if char == '{' or decoded_cookie[i:i+3] == '%7B':
                                        brace_count += 1
                                        if decoded_cookie[i:i+3] == '%7B':
                                            i += 2  # è·³è¿‡ %7B çš„å…¶ä½™éƒ¨åˆ†
                                    elif char == '}' or decoded_cookie[i:i+3] == '%7D':
                                        brace_count -= 1
                                        if decoded_cookie[i:i+3] == '%7D':
                                            i += 2
                                        if brace_count == 0:
                                            value_end = i + 1
                                            break
                                    elif char == ';' and brace_count == 0:
                                        value_end = i
                                        break
                                        
                                value_end = i + 1
                        else:
                            # æ™®é€šå€¼ï¼šæ‰¾åˆ°ä¸‹ä¸€ä¸ªåˆ†å·æˆ–å­—ç¬¦ä¸²ç»“å°¾
                            value_end = decoded_cookie.find(';', value_start)
                            if value_end == -1:
                                value_end = len(decoded_cookie)
                        
                        # æå–å€¼
                        value = decoded_cookie[value_start:value_end].strip()
                        
                        # å¤„ç†å€¼çš„URLè§£ç 
                        if key and value:
                            try:
                                # å¯¹äºJSONæ ¼å¼çš„Cookieå€¼ï¼Œè°¨æ…å¤„ç†URLè§£ç 
                                if value.startswith('%7B') or value.startswith('{'):
                                    # å°è¯•è§£ç ï¼Œä½†å¦‚æœå¤±è´¥å°±ä¿æŒåŸæ ·
                                    try:
                                        decoded_value = urllib.parse.unquote(value)
                                        # éªŒè¯è§£ç åçš„JSONæ˜¯å¦æœ‰æ•ˆ
                                        if decoded_value.startswith('{') and decoded_value.endswith('}'):
                                            json.loads(decoded_value)  # éªŒè¯JSONæ ¼å¼
                                    except:
                                        decoded_value = value  # è§£ç å¤±è´¥ï¼Œä¿æŒåŸæ ·
                                else:
                                    # æ™®é€šå€¼ï¼Œç›´æ¥è§£ç 
                                    decoded_value = urllib.parse.unquote(value)
                                
                                cookies_dict[key] = decoded_value
                                self.session.cookies.set(key, decoded_value)
                                print(f"  â†’ è®¾ç½®Cookie: {key}={decoded_value[:50]}...")
                                cookie_count += 1
                                
                            except Exception as decode_error:
                                print(f"  Ã— è·³è¿‡æ— æ•ˆCookie: {key} (è§£ç é”™è¯¯: {decode_error})")
                        
                        # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªCookie
                        current_pos = value_end
                        if current_pos < len(decoded_cookie) and decoded_cookie[current_pos] == ';':
                            current_pos += 1
                    
                    print(f"æˆåŠŸè§£æ {cookie_count} ä¸ªCookie")
                    return cookie_count
                    
            except Exception as e:
                print(f"Cookieæ–‡ä»¶è§£æé”™è¯¯: {e}")
        
        return 0
    
    def check_login(self):
        """æ£€æŸ¥ç™»å½•çŠ¶æ€"""
        self.author_backend_url = "https://my.jjwxc.net/backend/oneauthor_login.php"
        try:
            print("æ­£åœ¨æ£€æŸ¥ç™»å½•çŠ¶æ€...")
            response = self.session.get(self.author_backend_url, headers=self.headers, timeout=15)
            response.encoding = 'gb18030'
            html = response.text

            # åˆ¤æ–­é¡µé¢æ˜¯å¦åŒ…å«ç™»å½•æç¤º
            if "æ™‹æ±Ÿæ–‡å­¦åŸ" in html:
                print("ç™»å…¥æˆåŠŸ")
                return True
            elif "è¯·ç™»å½•" in html or "ç™»å½•æ™‹æ±Ÿä½œè€…åå°" in html or "è´¦å·" in html:
                print("æœªç™»å½•æ™‹æ±Ÿä½œè€…åå°ï¼Œè¯·æ£€æŸ¥Cookieæ˜¯å¦æœ‰æ•ˆ")
                return False
        except Exception as e:
            print(f"æ£€æŸ¥ç™»å½•çŠ¶æ€æ—¶å‡ºé”™: {e}")
            return False
        
    def get_novel_list(self):
        """è·å–ä½œè€…ä½œå“åˆ—è¡¨"""
        author_url = "https://my.jjwxc.net/backend/oneauthor_login.php"
        
        try:
            print(f"è·å–ä½œå“åˆ—è¡¨: {author_url}")
            response = self.session.get(author_url, headers=self.headers, timeout=20)
            
            # è®¾ç½®æ­£ç¡®çš„ç¼–ç 
            response.encoding = 'gb18030'  # æ™‹æ±Ÿä½¿ç”¨gb18030ç¼–ç 
            
            soup = BeautifulSoup(response.content, 'html.parser', from_encoding='gb18030')
            novels = []
            
            # ä¿å­˜é¡µé¢ç”¨äºè°ƒè¯•ï¼ˆå·²ç¦ç”¨ï¼Œå¦‚éœ€è°ƒè¯•è¯·å–æ¶ˆæ³¨é‡Šï¼‰
            # with open(os.path.join(self.output_dir, "novel_list.html"), "w", encoding="utf-8") as f:
            #     f.write(response.text)
            # print("ä½œå“åˆ—è¡¨é¡µé¢å·²ä¿å­˜: novel_list.html")
            
            # æŸ¥æ‰¾ä½œå“ç®¡ç†é“¾æ¥
            # åœ¨æ™‹æ±Ÿåå°ï¼Œä½œå“ç®¡ç†é“¾æ¥çš„æ ¼å¼æ˜¯: managenovel.php?novelid=XXXXX
            novel_links = soup.find_all('a', href=lambda x: x and 'managenovel.php?novelid=' in x)
            
            if novel_links:
                print(f"æ‰¾åˆ° {len(novel_links)} ä¸ªä½œå“ç®¡ç†é“¾æ¥")
                
                for link in novel_links:
                    # æå–ä½œå“ID
                    href = link['href']
                    novel_id_match = re.search(r'novelid=(\d+)', href)
                    if novel_id_match:
                        novel_id = novel_id_match.group(1)
                        
                        # æŸ¥æ‰¾ä½œå“æ ‡é¢˜ï¼ˆåœ¨åŒä¸€è¡Œçš„å…¶ä»–ä½ç½®ï¼‰
                        row = link.find_parent('tr')
                        if row:
                            # æŸ¥æ‰¾ä½œå“æ ‡é¢˜é“¾æ¥ï¼ˆæŒ‡å‘onebook.phpçš„é“¾æ¥ï¼‰
                            title_link = row.find('a', href=lambda x: x and f'onebook.php?novelid={novel_id}' in x)
                            if title_link:
                                title = title_link.get_text(strip=True)
                                
                        # æå–å…¶ä»–ä¿¡æ¯
                        cells = row.find_all('td')
                        if len(cells) >= 10:
                            try:
                                # æ ¹æ®HTMLç»“æ„æå–ä¿¡æ¯
                                category = cells[2].get_text(strip=True) if len(cells) > 2 else "æœªçŸ¥"
                                subcategory = cells[3].get_text(strip=True) if len(cells) > 3 else "æœªçŸ¥"
                                chapter_count = cells[5].get_text(strip=True) if len(cells) > 5 else "0"
                                word_count = cells[6].get_text(strip=True) if len(cells) > 6 else "0"
                                status = cells[12].get_text(strip=True) if len(cells) > 12 else "æœªçŸ¥"
                                
                                novels.append({
                                    'id': novel_id,
                                    'title': title,
                                    'link': href,
                                    'view_link': title_link['href'],
                                    'status': status,
                                    'word_count': word_count,
                                    'chapter_count': chapter_count,
                                    'category': f"{category}-{subcategory}"
                                })
                                
                            except Exception as e:
                                print(f"è§£æä½œå“ä¿¡æ¯å‡ºé”™ {novel_id}: {e}")
                                novels.append({
                                    'id': novel_id,
                                    'title': title,
                                    'link': href,
                                    'view_link': title_link['href'],
                                    'status': "æœªçŸ¥",
                                    'word_count': "æœªçŸ¥",
                                    'chapter_count': "æœªçŸ¥",
                                    'category': "æœªçŸ¥"
                                })
                
                print(f"æˆåŠŸè§£æ {len(novels)} éƒ¨ä½œå“")
                return novels
            else:
                print("æœªæ‰¾åˆ°ä½œå“ç®¡ç†é“¾æ¥")
                # å¤‡ç”¨æ–¹æ³•ï¼šæŸ¥æ‰¾onebook.phpé“¾æ¥
                onebook_links = soup.find_all('a', href=lambda x: x and 'onebook.php?novelid=' in x)
                if onebook_links:
                    print(f"æ‰¾åˆ° {len(onebook_links)} ä¸ªä½œå“é˜…è¯»é“¾æ¥")
                    for idx, link in enumerate(onebook_links):
                        href = link['href']
                        novel_id_match = re.search(r'novelid=(\d+)', href)
                        if novel_id_match:
                            novel_id = novel_id_match.group(1)
                            title = link.get_text(strip=True)
                            
                            novels.append({
                                'id': novel_id,
                                'title': title,
                                'link': f"//my.jjwxc.net/backend/managenovel.php?novelid={novel_id}",
                                'view_link': href,
                                'status': "æœªçŸ¥",
                                'word_count': "æœªçŸ¥",
                                'chapter_count': "æœªçŸ¥",
                                'category': "æœªçŸ¥"
                            })
                    
                    return novels
                else:
                    print("ä¹Ÿæœªæ‰¾åˆ°ä½œå“é˜…è¯»é“¾æ¥")
                    return []
            
        except Exception as e:
            print(f"è·å–ä½œå“åˆ—è¡¨å‡ºé”™: {str(e)}")
            return []
    
    def get_intro_from_backend(self, novel_id):
        """ä»ä½œè€…åå°è·å–ä½œå“ç®€ä»‹"""
        try:
            backend_url = f"https://my.jjwxc.net/backend/managenovel.php?novelid={novel_id}"
            print(f"è®¿é—®åå°ç« èŠ‚ç®¡ç†é¡µé¢: {backend_url}")
            headers = self.headers.copy()
            headers['Referer'] = 'https://my.jjwxc.net/backend/'
            response = self.session.get(backend_url, headers=headers, timeout=30)
            response.encoding = 'gb18030'
            
            soup = BeautifulSoup(response.content, 'html.parser', from_encoding='gb18030')
            novel_intro = ""
            intro_textarea = soup.find('textarea', {'id': 'novelintro'})
            if intro_textarea:
                novel_intro = intro_textarea.get_text(strip=True)
                print(f"è·å–åˆ°ä½œå“ç®€ä»‹: {len(novel_intro)} å­—ç¬¦")
            return novel_intro
        except Exception as e:
            print(f"è·å–ä½œå“ç®€ä»‹å¤±è´¥: {e}")
            return ""

    def get_chapters(self, novel_link):
        """
        è·å–ä½œå“çš„å®Œæ•´ç« èŠ‚åˆ—è¡¨
        
        å‚æ•°ï¼š
            novel_link (str): ä½œå“ç®¡ç†é¡µé¢é“¾æ¥
            
        è¿”å›ï¼š
            list: ç« èŠ‚ä¿¡æ¯åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«ï¼š
                - id: ç« èŠ‚ID
                - title: ç« èŠ‚æ ‡é¢˜  
                - link: ç« èŠ‚è®¿é—®é“¾æ¥
                - chapter_number: ç« èŠ‚ç¼–å·
                - is_vip: æ˜¯å¦VIPç« èŠ‚
                
        åŠŸèƒ½æµç¨‹ï¼š
        1. ä»é“¾æ¥æå–ä½œå“ID
        2. è®¿é—®åå°ç« èŠ‚ç®¡ç†é¡µé¢
        3. è§£æç« èŠ‚è¡¨æ ¼ï¼ˆåŒ…æ‹¬éšè—è¡Œï¼‰
        4. åŒºåˆ†å…è´¹å’ŒVIPç« èŠ‚
        5. æŒ‰ç« èŠ‚ç¼–å·æ’åº
        
        ç« èŠ‚è¯†åˆ«é€»è¾‘ï¼š
        - VIPç« èŠ‚ï¼šé“¾æ¥åŒ…å«'onebook_vip.php'
        - å…è´¹ç« èŠ‚ï¼šå…¶ä»–ç« èŠ‚
        - éšè—ç« èŠ‚ï¼šåŒ…æ‹¬display:noneçš„è¡Œ
        """
        if not novel_link:
            return []
            
        try:
            # æå–novelid
            novel_id_match = re.search(r'novelid=(\d+)', novel_link)
            if not novel_id_match:
                print(f"æ— æ³•ä»é“¾æ¥ä¸­æå–ä½œå“ID: {novel_link}")
                return []
            novel_id = novel_id_match.group(1)
            backend_url = f"https://my.jjwxc.net/backend/managenovel.php?novelid={novel_id}"
            print(f"è·å–æ‰€æœ‰ç« èŠ‚åˆ—è¡¨: {backend_url}")
            response = self.session.get(backend_url, headers=self.headers, timeout=30)
            response.encoding = 'gb18030'
            
            soup = BeautifulSoup(response.content, 'html.parser', from_encoding='gb18030')
            chapters = []
            
            # æŸ¥æ‰¾ç« èŠ‚è¡¨æ ¼ï¼ŒåŒ…æ‹¬éšè—çš„ç« èŠ‚è¡Œ
            # æŸ¥æ‰¾æ‰€æœ‰åŒ…å«ç« èŠ‚ä¿¡æ¯çš„trè¡Œï¼ŒåŒ…æ‹¬style="display:none;"çš„éšè—è¡Œ
            chapter_rows = soup.find_all('tr', {'bgcolor': '#eefaee'})
            
            for tr in chapter_rows:
                # æŸ¥æ‰¾ç« èŠ‚ID input
                chapter_id_input = tr.find('input', {'name': 'chapterid'})
                if not chapter_id_input:
                    continue
                    
                chapter_id = chapter_id_input.get('value')
                if not chapter_id:
                    continue
                
                # æŸ¥æ‰¾ç« èŠ‚æ ‡é¢˜é“¾æ¥
                title_link = tr.find('a', href=True)
                if not title_link:
                    continue
                    
                title = title_link.get_text(strip=True)
                href = title_link.get('href')
                
                # åˆ¤æ–­æ˜¯å¦VIPç« èŠ‚ - é€šè¿‡é“¾æ¥æˆ–æ ‡é¢˜ä¸­çš„VIPæ ‡è¯†
                is_vip = False
                if 'onebook_vip.php' in href or '[VIP]' in title_link.get_text():
                    is_vip = True
                
                # æå–ç« èŠ‚ç¼–å·ï¼ˆä»ç¬¬äºŒä¸ªtdä¸­è·å–ï¼‰
                chapter_num_td = tr.find_all('td')[1]  # ç¬¬äºŒä¸ªtdåŒ…å«ç« èŠ‚ç¼–å·
                chapter_number = int(chapter_num_td.get_text(strip=True))
                
                # æ„å»ºå®Œæ•´çš„è®¿é—®é“¾æ¥
                if not href.startswith('http'):
                    if href.startswith('//'):
                        link = f"https:{href}"
                    else:
                        link = f"https://www.jjwxc.net{href}"
                else:
                    link = href
                
                chapters.append({
                    'id': chapter_id,
                    'title': title,
                    'link': link,
                    'chapter_number': chapter_number,
                    'is_vip': is_vip
                })
            
            # æŒ‰ç« èŠ‚ç¼–å·æ’åº
            chapters.sort(key=lambda x: x['chapter_number'])
            
            vip_count = sum(1 for c in chapters if c['is_vip'])
            free_count = len(chapters) - vip_count
            print(f"æˆåŠŸè§£æ {len(chapters)} ä¸ªç« èŠ‚ï¼Œå…¶ä¸­å…è´¹ç« èŠ‚æ•°é‡ï¼š{free_count}ï¼ŒVIPç« èŠ‚æ•°é‡ï¼š{vip_count}")
            return chapters
        except Exception as e:
            print(f"è·å–ç« èŠ‚åˆ—è¡¨å‡ºé”™: {str(e)}")
            return []
    
    def get_chapter_content(self, chapter_link, is_vip=False):
        """
        è·å–ç« èŠ‚å†…å®¹ï¼ˆæ”¯æŒå…è´¹å’ŒVIPç« èŠ‚ï¼‰
        
        å‚æ•°ï¼š
            chapter_link (str): ç« èŠ‚é“¾æ¥
            is_vip (bool): æ˜¯å¦ä¸ºVIPç« èŠ‚
            
        è¿”å›ï¼š
            str: ç« èŠ‚å®Œæ•´å†…å®¹ï¼ˆåŒ…å«æ­£æ–‡å’Œä½œè€…æœ‰è¯è¯´ï¼‰
            
        å…è´¹ç« èŠ‚å¤„ç†ï¼š
        1. ç›´æ¥è®¿é—®ç« èŠ‚é¡µé¢
        2. è§£ænovelbody divä¸­çš„æ­£æ–‡å†…å®¹
        3. è§£ænote_str divä¸­çš„ä½œè€…æœ‰è¯è¯´
        4. ä¿ç•™æ¢è¡Œæ ¼å¼å’ŒHTMLç»“æ„
        
        VIPç« èŠ‚å¤„ç†ï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰ï¼š
        1. ä»ç« èŠ‚é“¾æ¥æå–novelidå’Œchapterid
        2. æ„å»ºåå°ç¼–è¾‘é¡µé¢URL (chaptermodify.php)
        3. ä»textareaè·å–æœªåŠ å¯†çš„åŸå§‹å†…å®¹ï¼š
           - name='content': ç« èŠ‚æ­£æ–‡
           - name='note': ä½œè€…æœ‰è¯è¯´
        4. å®Œæ•´ä¿ç•™åŸå§‹æ ¼å¼ï¼ˆæ¢è¡Œã€ç©ºè¡Œã€ç‰¹æ®Šå­—ç¬¦ï¼‰
        5. æ¸…ç†HTMLå®ä½“ç¼–ç ä½†ä¿æŒæ–‡æœ¬ç»“æ„
        
        æ ¼å¼ä¿ç•™ç­–ç•¥ï¼š
        - ä½¿ç”¨textarea.stringè·å–åŸå§‹æ–‡æœ¬
        - ä¿ç•™æ‰€æœ‰\næ¢è¡Œç¬¦å’Œç©ºè¡Œ
        - åªå¤„ç†HTMLå®ä½“è½¬ä¹‰ï¼ˆ&lt; &gt; &amp;ç­‰ï¼‰
        - ä¸åšé¢å¤–çš„æ–‡æœ¬æ¸…ç†æˆ–æ ¼å¼åŒ–
        
        é”™è¯¯å¤„ç†ï¼š
        - é“¾æ¥æ— æ•ˆï¼šè¿”å›é”™è¯¯ä¿¡æ¯
        - ç½‘ç»œå¼‚å¸¸ï¼šè¿”å›å¼‚å¸¸æè¿°
        - å†…å®¹ä¸ºç©ºï¼šè¿”å›è·å–å¤±è´¥æç¤º
        """
        if not chapter_link:
            return "ç« èŠ‚é“¾æ¥æ— æ•ˆ"
        try:
            # å…è´¹ç« èŠ‚å¤„ç†é€»è¾‘
            if not is_vip:
                if not chapter_link.startswith('http'):
                    chapter_link = f"https://www.jjwxc.net{chapter_link}"
                print(f"  è·å–å…è´¹ç« èŠ‚å†…å®¹...")
                response = self.session.get(chapter_link, headers=self.headers, timeout=30)
                response.encoding = 'gb18030'
                soup = BeautifulSoup(response.content, 'html.parser', from_encoding='gb18030')
                main_content = ""
                novelbody_div = soup.find('div', class_='novelbody')
                if novelbody_div:
                    text_container = novelbody_div.select_one('div > div')
                    if text_container:
                        content_parts = []
                        for element in text_container.children:
                            if getattr(element, 'name', None) == 'br':
                                content_parts.append('\n')
                            elif getattr(element, 'string', None) and element.string.strip():
                                content_parts.append(element.string.strip())
                        main_content = ''.join(content_parts)
                author_notes = ""
                note_wrapper = soup.find('div', id='note_danmu_wrapper')
                if note_wrapper:
                    note_str = note_wrapper.find('div', id='note_str')
                    if note_str:
                        html_content = str(note_str)
                        html_content = re.sub(r'<br\s*/?>', '\n', html_content, flags=re.IGNORECASE)
                        clean_soup = BeautifulSoup(html_content, 'html.parser')
                        author_notes = clean_soup.get_text(strip=True)
                result_parts = []
                if main_content and len(main_content) > 20:
                    result_parts.append(main_content)
                if author_notes and len(author_notes) > 10:
                    result_parts.append('\n\nã€ä½œè€…æœ‰è¯è¯´ã€‘')
                    result_parts.append(author_notes)
                if result_parts:
                    result = ''.join(result_parts)
                    if len(result.strip()) > 30:
                        return result
                return "å†…å®¹è·å–å¤±è´¥ï¼šæœªæ‰¾åˆ°æœ‰æ•ˆå†…å®¹"
            # VIPç« èŠ‚å¤„ç†é€»è¾‘ - ä»ä½œè€…åå°ç¼–è¾‘é¡µé¢è·å–æœªåŠ å¯†å†…å®¹
            else:
                # ä»ç« èŠ‚é“¾æ¥ä¸­æå–novelidå’Œchapterid
                novel_id_match = re.search(r'novelid=(\d+)', chapter_link)
                chapter_id_match = re.search(r'chapterid=(\d+)', chapter_link)
                
                if not novel_id_match or not chapter_id_match:
                    return "VIPç« èŠ‚é“¾æ¥æ ¼å¼é”™è¯¯"
                
                novel_id = novel_id_match.group(1)
                chapter_id = chapter_id_match.group(1)
                
                # æ„å»ºåå°ç¼–è¾‘é¡µé¢é“¾æ¥
                edit_url = f"https://my.jjwxc.net/backend/chaptermodify.php?novelid={novel_id}&chapterid={chapter_id}"
                print(f"  è·å–VIPç« èŠ‚å†…å®¹ï¼ˆä»ç¼–è¾‘é¡µé¢ï¼‰...")
                
                headers = self.headers.copy()
                headers['Referer'] = f'https://my.jjwxc.net/backend/managenovel.php?novelid={novel_id}'
                
                response = self.session.get(edit_url, headers=headers, timeout=30)
                response.encoding = 'gb18030'
                soup = BeautifulSoup(response.content, 'html.parser', from_encoding='gb18030')
                
                main_content = ""
                author_notes = ""
                
                # ä»ç¼–è¾‘é¡µé¢çš„textareaè·å–æ­£æ–‡å†…å®¹
                chapterbody_textarea = soup.find('textarea', {'name': 'content'})
                if chapterbody_textarea:
                    # è·å–åŸå§‹æ–‡æœ¬å†…å®¹ï¼Œä¿ç•™æ‰€æœ‰æ ¼å¼
                    main_content = chapterbody_textarea.string or chapterbody_textarea.get_text()
                    # å¦‚æœæ²¡æœ‰å†…å®¹ï¼Œå°è¯•ä»textareaå†…éƒ¨è·å–
                    if not main_content.strip():
                        main_content = ''.join(str(content) for content in chapterbody_textarea.contents)
                    
                    # åªæ¸…ç†HTMLå®ä½“ç¼–ç ï¼Œä¿ç•™æ‰€æœ‰æ¢è¡Œå’Œç©ºè¡Œ
                    main_content = main_content.replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')
                    main_content = main_content.replace('&quot;', '"').replace('&#039;', "'")
                    main_content = main_content.replace('&nbsp;', ' ')  # å¤„ç†éæ–­è¡Œç©ºæ ¼
                
                # è·å–ä½œè€…æœ‰è¯è¯´
                authornote_textarea = soup.find('textarea', {'name': 'note'})
                if authornote_textarea:
                    # è·å–åŸå§‹æ–‡æœ¬å†…å®¹ï¼Œä¿ç•™æ‰€æœ‰æ ¼å¼
                    author_notes = authornote_textarea.string or authornote_textarea.get_text()
                    # å¦‚æœæ²¡æœ‰å†…å®¹ï¼Œå°è¯•ä»textareaå†…éƒ¨è·å–
                    if not author_notes.strip():
                        author_notes = ''.join(str(content) for content in authornote_textarea.contents)
                    
                    # åªæ¸…ç†HTMLå®ä½“ç¼–ç ï¼Œä¿ç•™æ‰€æœ‰æ¢è¡Œå’Œç©ºè¡Œ
                    author_notes = author_notes.replace('&lt;', '<').replace('&gt;', '>').replace('&amp;', '&')
                    author_notes = author_notes.replace('&quot;', '"').replace('&#039;', "'")
                    author_notes = author_notes.replace('&nbsp;', ' ')  # å¤„ç†éæ–­è¡Œç©ºæ ¼
                
                result_parts = []
                if main_content and len(main_content.strip()) > 20:
                    result_parts.append(main_content)
                if author_notes and len(author_notes.strip()) > 10:
                    result_parts.append('\n\nã€ä½œè€…æœ‰è¯è¯´ã€‘\n')
                    result_parts.append(author_notes)
                if result_parts:
                    result = ''.join(result_parts)
                    if len(result.strip()) > 30:
                        return result
                return "VIPå†…å®¹è·å–å¤±è´¥ï¼šæœªæ‰¾åˆ°æœ‰æ•ˆå†…å®¹"
        except Exception as e:
            print(f"  ç« èŠ‚å†…å®¹è·å–å‡ºé”™: {str(e)}")
            return f"å†…å®¹è·å–å¤±è´¥ï¼š{str(e)}"

    def create_docx_with_realtime_save(self, novel, chapters):
        """
        åˆ›å»ºDOCXæ–‡æ¡£å¹¶å®æ—¶ä¿å­˜ç« èŠ‚å†…å®¹
        
        å‚æ•°ï¼š
            novel (dict): ä½œå“ä¿¡æ¯å­—å…¸
            chapters (list): ç« èŠ‚åˆ—è¡¨
            
        åŠŸèƒ½ç‰¹æ€§ï¼š
        1. æ–‡æ¡£ç»“æ„åˆ›å»ºï¼š
           - ä½œå“æ ‡é¢˜ï¼ˆ0çº§æ ‡é¢˜ï¼Œå±…ä¸­ï¼‰
           - ä½œå“ä¿¡æ¯ï¼ˆIDã€å­—æ•°ã€çŠ¶æ€ï¼‰
           - ä½œå“ç®€ä»‹ï¼ˆä»åå°è·å–ï¼‰
           - åˆ†é¡µç¬¦åˆ†éš”
           
        2. ç« èŠ‚å¤„ç†ï¼š
           - é€ç« èŠ‚è·å–å’Œæ·»åŠ å†…å®¹
           - å®æ—¶ä¿å­˜ï¼ˆæ¯ç« èŠ‚ä¿å­˜ä¸€æ¬¡ï¼‰
           - ç« èŠ‚æ ‡é¢˜æ ¼å¼åŒ–ï¼ˆç¬¬Xç«  æ ‡é¢˜ï¼‰
           - ç« èŠ‚é—´åˆ†éš”ç¬¦
           
        3. å†…å®¹æ ¼å¼åŒ–ï¼š
           - è°ƒç”¨_add_content_to_docå¤„ç†æ­£æ–‡
           - è‡ªåŠ¨åˆ†ç¦»ä½œè€…æœ‰è¯è¯´
           - ä¿ç•™åŸå§‹æ¢è¡Œå’Œç©ºè¡Œ
           - é”™è¯¯ç« èŠ‚æ ‡çº¢æ˜¾ç¤º
           
        4. å®æ—¶ä¿å­˜æœºåˆ¶ï¼š
           - åˆ›å»ºåˆå§‹æ–‡æ¡£ç»“æ„ç«‹å³ä¿å­˜
           - æ¯æ·»åŠ ä¸€ç« èŠ‚å†…å®¹åä¿å­˜
           - ç”¨æˆ·å¯éšæ—¶æ‰“å¼€æŸ¥çœ‹è¿›åº¦
           - é¿å…ç¨‹åºä¸­æ–­å¯¼è‡´æ•°æ®ä¸¢å¤±
           
        5. æ–‡ä»¶å‘½åï¼š
           - æ¸…ç†æ ‡é¢˜ä¸­çš„éæ³•å­—ç¬¦
           - ç”Ÿæˆsafeçš„æ–‡ä»¶å
           - ä¿å­˜åˆ°backup/timestamp/ç›®å½•
           
        6. é”™è¯¯å¤„ç†ï¼š
           - ç« èŠ‚è·å–å¤±è´¥ï¼šæ ‡çº¢æ˜¾ç¤ºé”™è¯¯ä¿¡æ¯
           - ç½‘ç»œå¼‚å¸¸ï¼šç»§ç»­å¤„ç†ä¸‹ä¸€ç« èŠ‚
           - æ–‡æ¡£ä¿å­˜å¼‚å¸¸ï¼šè®°å½•é”™è¯¯å¹¶ç»§ç»­
           
        7. è¿›åº¦æ˜¾ç¤ºï¼š
           - æ˜¾ç¤ºå½“å‰ç« èŠ‚è¿›åº¦ [X/æ€»æ•°]
           - é¢„ä¼°å‰©ä½™æ—¶é—´
           - ç« èŠ‚è·å–çŠ¶æ€åé¦ˆ
        """
        if not chapters:
            print(f"æ²¡æœ‰æ‰¾åˆ°ç« èŠ‚å†…å®¹ï¼Œè·³è¿‡ {novel['title']}")
            return
        
        try:
            # åˆ›å»ºWordæ–‡æ¡£
            doc = Document()
            
            # æ·»åŠ ä½œå“æ ‡é¢˜ï¼ˆæœ€é«˜çº§æ ‡é¢˜ï¼‰
            title_paragraph = doc.add_heading(novel['title'], level=0)
            title_paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
            
            # æ·»åŠ ä½œå“åŸºæœ¬ä¿¡æ¯
            info_paragraph = doc.add_paragraph()
            info_paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
            
            info_run = info_paragraph.add_run(
                f"ä½œå“ID: {novel['id']} | "
                f"å­—æ•°: {novel.get('word_count', 'æœªçŸ¥')} | "
                f"çŠ¶æ€: {novel.get('status', 'æœªçŸ¥')}"
            )
            info_run.font.size = Pt(10)
            
            # è·å–ä½œå“ç®€ä»‹å¹¶æ’å…¥åˆ°çŠ¶æ€ä¸‹æ–¹
            novel_intro = self.get_intro_from_backend(novel['id'])
            if novel_intro:
                intro_paragraph = doc.add_paragraph(novel_intro)
                intro_paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
                intro_paragraph.runs[0].font.size = Pt(11)
            
            # æ·»åŠ åˆ†é¡µç¬¦
            doc.add_page_break()
            
            # å‡†å¤‡æ–‡ä»¶åå’Œè·¯å¾„
            filename = self._clean_filename(novel['title'])
            filepath = os.path.join(self.output_dir, f"{filename}.docx")
            
            total_chapters = len(chapters)
            print(f"å¼€å§‹å¤„ç†: {novel['title']} ({total_chapters}ç« )")
            print(f"æ–‡æ¡£å°†ä¿å­˜ä¸º: {filepath}")
            
            # å…ˆä¿å­˜åˆå§‹æ–‡æ¡£ç»“æ„
            doc.save(filepath)
            print(f"âœ“ å·²åˆ›å»ºåˆå§‹æ–‡æ¡£ï¼Œå¯ä»¥æ‰“å¼€æŸ¥çœ‹")
            
            # é€ç« èŠ‚å¤„ç†å¹¶å®æ—¶ä¿å­˜
            for idx, chapter in enumerate(chapters):
                try:
                    # æ·»åŠ ç« èŠ‚æ ‡é¢˜ï¼ˆå¸¦ç« èŠ‚ç¼–å·ï¼‰
                    chapter_title = f"ç¬¬{chapter.get('chapter_number', idx+1)}ç«  {chapter['title']}"
                    doc.add_heading(chapter_title, level=1)
                    
                    # è·å–ç« èŠ‚å†…å®¹
                    print(f"æ­£åœ¨è·å–: {chapter_title} [{idx+1}/{total_chapters}]")
                    content = self.get_chapter_content(chapter['link'], chapter.get('is_vip', False))
                    
                    # æ£€æŸ¥å†…å®¹æ˜¯å¦æœ‰æ•ˆ
                    if content and not content.startswith("å†…å®¹è·å–å¤±è´¥") and not content.startswith("ç« èŠ‚é“¾æ¥æ— æ•ˆ"):
                        self._add_content_to_doc(doc, content)
                    else:
                        # å†…å®¹è·å–å¤±è´¥çš„æƒ…å†µ
                        error_paragraph = doc.add_paragraph(f"[ç« èŠ‚å†…å®¹è·å–å¤±è´¥: {content}]")
                        error_paragraph.runs[0].font.color.rgb = RGBColor(255, 0, 0)
                    
                    # æ·»åŠ ç« èŠ‚åˆ†éš”ç¬¦
                    if idx < total_chapters - 1:
                        doc.add_paragraph()
                        separator = doc.add_paragraph("â”€" * 50)
                        separator.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
                        doc.add_paragraph()
                    
                    # å®æ—¶ä¿å­˜æ–‡æ¡£
                    doc.save(filepath)
                    print(f"âœ“ å·²ä¿å­˜ [{idx+1}/{total_chapters}]")
                    
                except Exception as e:
                    print(f"å¤„ç†ç« èŠ‚å‡ºé”™: {str(e)}")
                    error_paragraph = doc.add_paragraph(f"[ç« èŠ‚å¤„ç†é”™è¯¯: {chapter['title']} - {str(e)}]")
                    error_paragraph.runs[0].font.color.rgb = RGBColor(255, 0, 0)
                    doc.save(filepath)
                
                # å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(random.uniform(1.0, 2.0))
            
            print(f"âœ“ å®Œæˆä¿å­˜: {novel['title']}")
            
        except Exception as e:
            print(f"åˆ›å»ºæ–‡æ¡£å‡ºé”™: {str(e)}")
    
    def _clean_filename(self, filename):
        """æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
        invalid_chars = '<>:"/\\|?*'
        for char in invalid_chars:
            filename = filename.replace(char, '_')
        
        if not filename.strip() or filename.strip() == '_':
            filename = f"novel_{int(time.time())}"
        
        return filename
    
    def _add_content_to_doc(self, doc, content):
        """
        å°†ç« èŠ‚å†…å®¹æ·»åŠ åˆ°DOCXæ–‡æ¡£ä¸­ï¼ˆæ ¼å¼ä¿ç•™ç‰ˆï¼‰
        
        å‚æ•°ï¼š
            doc: python-docx Documentå¯¹è±¡
            content (str): ç« èŠ‚å®Œæ•´å†…å®¹
            
        åŠŸèƒ½ï¼š
        1. å†…å®¹åˆ†ç¦»ï¼š
           - ä»¥ã€ä½œè€…æœ‰è¯è¯´ã€‘ä¸ºåˆ†ç•Œç‚¹
           - åˆ†ç¦»æ­£æ–‡å’Œä½œè€…æœ‰è¯è¯´ä¸¤éƒ¨åˆ†
           - å»é™¤é¦–å°¾ç©ºç™½ä½†ä¿ç•™å†…éƒ¨æ ¼å¼
           
        2. æ­£æ–‡å¤„ç†ï¼š
           - æŒ‰æ¢è¡Œç¬¦(\n)åˆ†å‰²ä¸ºè¡Œ
           - æ¯è¡Œåˆ›å»ºç‹¬ç«‹æ®µè½
           - å®Œæ•´ä¿ç•™ç©ºè¡Œï¼ˆç©ºæ®µè½ï¼‰
           - ä¸åšä»»ä½•æ–‡æœ¬æ¸…ç†æˆ–å»ç©ºæ ¼
           
        3. ä½œè€…æœ‰è¯è¯´å¤„ç†ï¼š
           - æ·»åŠ è“è‰²äºŒçº§æ ‡é¢˜"ä½œè€…æœ‰è¯è¯´"
           - åŒæ ·æŒ‰è¡Œå¤„ç†å†…å®¹
           - ä¿æŒä¸æ­£æ–‡ç›¸åŒçš„æ ¼å¼å¤„ç†æ–¹å¼
           
        æ ¼å¼ä¿ç•™ç­–ç•¥ï¼ˆæ ¸å¿ƒï¼‰ï¼š
        - split('\n')ï¼šä¸¥æ ¼æŒ‰æ¢è¡Œç¬¦åˆ†å‰²
        - ä¸ä½¿ç”¨strip()ï¼šä¿ç•™æ¯è¡ŒåŸå§‹å†…å®¹
        - ç©ºè¡Œå¤„ç†ï¼šåˆ›å»ºç©ºæ®µè½ä¿æŒç‰ˆå¼
        - æ®µè½ç‹¬ç«‹ï¼šæ¯è¡Œä¸€ä¸ªæ®µè½ç¡®ä¿æ¢è¡Œæ•ˆæœ
        
        ä¸ä¹‹å‰ç‰ˆæœ¬åŒºåˆ«ï¼š
        - æ—§ç‰ˆï¼šå¤æ‚çš„æ®µè½å’Œæ¢è¡Œå¤„ç†ï¼Œå®¹æ˜“ä¸¢å¤±æ ¼å¼
        - æ–°ç‰ˆï¼šç®€å•çš„è¡Œçº§å¤„ç†ï¼Œå®Œç¾ä¿ç•™åŸå§‹æ ¼å¼
        
        ä½¿ç”¨åœºæ™¯ï¼š
        - VIPç« èŠ‚ï¼šä¿ç•™ä»åå°è·å–çš„åŸå§‹æ ¼å¼
        - å…è´¹ç« èŠ‚ï¼šä¿ç•™ä»é¡µé¢è§£æçš„æ ¼å¼
        - ä½œè€…æœ‰è¯è¯´ï¼šä¿ç•™ç‰¹æ®Šæ ¼å¼å’Œæ¢è¡Œ
        """
        # åˆ†ç¦»æ­£æ–‡å’Œä½œè€…æœ‰è¯è¯´
        main_text = ""
        author_notes = ""
        
        if 'ã€ä½œè€…æœ‰è¯è¯´ã€‘' in content:
            parts = content.split('ã€ä½œè€…æœ‰è¯è¯´ã€‘', 1)
            main_text = parts[0].strip()
            if len(parts) > 1:
                author_notes = parts[1].strip()
        else:
            main_text = content.strip()
        
        # æ·»åŠ æ­£æ–‡å†…å®¹
        if main_text:
            # æŒ‰è¡Œåˆ†å‰²ï¼Œä¿ç•™æ‰€æœ‰æ¢è¡Œç¬¦å’Œç©ºè¡Œ
            lines = main_text.split('\n')
            for line in lines:
                # ä¿ç•™åŸå§‹å†…å®¹ï¼ŒåŒ…æ‹¬ç©ºè¡Œ
                doc.add_paragraph(line)
        
        # æ·»åŠ ä½œè€…æœ‰è¯è¯´éƒ¨åˆ†
        if author_notes:
            author_heading = doc.add_heading('ä½œè€…æœ‰è¯è¯´', level=2)
            author_heading.runs[0].font.color.rgb = RGBColor(0, 0, 255)
            
            # æŒ‰è¡Œåˆ†å‰²ï¼Œä¿ç•™æ‰€æœ‰æ¢è¡Œç¬¦å’Œç©ºè¡Œ
            lines = author_notes.split('\n')
            for line in lines:
                # ä¿ç•™åŸå§‹å†…å®¹ï¼ŒåŒ…æ‹¬ç©ºè¡Œ
                doc.add_paragraph(line)
    
    def select_novels_to_backup(self, novels):
        """ç”¨æˆ·é€‰æ‹©è¦å¤‡ä»½çš„ä½œå“"""
        if not novels:
            return []
        
        print("\n" + "="*50)
        print("å‘ç°ä»¥ä¸‹ä½œå“ï¼š")
        print("="*50)
        
        for idx, novel in enumerate(novels):
            print(f"{idx+1:2d}. {novel['title']}")
            print(f"     ID: {novel['id']} | å­—æ•°: {novel.get('word_count', 'æœªçŸ¥')} | çŠ¶æ€: {novel.get('status', 'æœªçŸ¥')}")
        
        print("\né€‰æ‹©æ–¹å¼ï¼š")
        print("  è¾“å…¥æ•°å­—é€‰æ‹©å•æœ¬ä½œå“ï¼ˆå¦‚ï¼š1ï¼‰")
        print("  è¾“å…¥å¤šä¸ªæ•°å­—é€‰æ‹©å¤šæœ¬ä½œå“ï¼ˆå¦‚ï¼š1,3,5ï¼‰")
        print("  è¾“å…¥ 'all' æˆ– 'a' å¤‡ä»½å…¨éƒ¨ä½œå“")
        print("  è¾“å…¥ 'quit' æˆ– 'q' é€€å‡ºç¨‹åº")
        
        while True:
            try:
                choice = input("\nè¯·è¾“å…¥é€‰æ‹©: ").strip().lower()
                
                if choice in ['quit', 'q']:
                    print("é€€å‡ºç¨‹åº")
                    return []
                
                if choice in ['all', 'a']:
                    print(f"é€‰æ‹©å¤‡ä»½å…¨éƒ¨ {len(novels)} éƒ¨ä½œå“")
                    return novels
                
                # è§£ææ•°å­—é€‰æ‹©
                selected_indices = []
                for item in choice.split(','):
                    item = item.strip()
                    if item.isdigit():
                        idx = int(item) - 1
                        if 0 <= idx < len(novels):
                            selected_indices.append(idx)
                        else:
                            print(f"æ•°å­— {item} è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°è¾“å…¥")
                            break
                    else:
                        print(f"æ— æ•ˆè¾“å…¥ '{item}'ï¼Œè¯·é‡æ–°è¾“å…¥")
                        break
                else:
                    if selected_indices:
                        selected_novels = [novels[i] for i in selected_indices]
                        print(f"é€‰æ‹©å¤‡ä»½ {len(selected_novels)} éƒ¨ä½œå“:")
                        for novel in selected_novels:
                            print(f"  - {novel['title']}")
                        return selected_novels
                    else:
                        print("æœªé€‰æ‹©ä»»ä½•ä½œå“ï¼Œè¯·é‡æ–°è¾“å…¥")
                        
            except KeyboardInterrupt:
                print("\n\nç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
                return []
            except Exception as e:
                print(f"è¾“å…¥é”™è¯¯: {e}ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def backup_all_novels(self):
        """å¤‡ä»½ä½œå“ä¸»æµç¨‹"""
        print("æ­£åœ¨åˆå§‹åŒ–...")
        
        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        self.check_login()
        
        # è·å–ä½œå“åˆ—è¡¨
        print("æ­£åœ¨è·å–ä½œå“åˆ—è¡¨...")
        novels = self.get_novel_list()
        
        if not novels:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä½œå“")
            return
        
        print(f"âœ“ æˆåŠŸè·å– {len(novels)} éƒ¨ä½œå“")
        
        # ç”¨æˆ·é€‰æ‹©è¦å¤‡ä»½çš„ä½œå“
        selected_novels = self.select_novels_to_backup(novels)
        if not selected_novels:
            return
        
        # ä¿å­˜ä½œå“åˆ—è¡¨ä¿¡æ¯
        with open(os.path.join(self.output_dir, "ä½œå“åˆ—è¡¨.json"), "w", encoding="utf-8") as f:
            json.dump(selected_novels, f, ensure_ascii=False, indent=2)
        
        total_novels = len(selected_novels)
        print(f"\n{'='*50}")
        print(f"å¼€å§‹å¤‡ä»½ {total_novels} éƒ¨ä½œå“")
        print(f"{'='*50}")
        
        # å¤‡ä»½æ¯éƒ¨ä½œå“
        for idx, novel in enumerate(selected_novels):
            print(f"\nâ–¶ [{idx+1}/{total_novels}] å¼€å§‹å¤‡ä»½: {novel['title']}")
            
            # è·å–ç« èŠ‚åˆ—è¡¨
            chapters = self.get_chapters(novel['link'])
            
            if chapters:
                # åˆ›å»ºDOCXæ–‡ä»¶
                self.create_docx_with_realtime_save(novel, chapters)
            else:
                print(f"âŒ æœªæ‰¾åˆ°ç« èŠ‚ï¼Œè·³è¿‡: {novel['title']}")
            
            # ä½œå“é—´å»¶è¿Ÿ
            if idx < total_novels - 1:
                delay = random.uniform(2.0, 4.0)
                print(f"ç­‰å¾… {delay:.1f} ç§’åç»§ç»­...")
                time.sleep(delay)
        
        print(f"\n{'='*50}")
        print(f"ğŸ‰ å¤‡ä»½å®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜åˆ°: {self.output_dir}")
        print(f"{'='*50}")


if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                  æ™‹æ±Ÿæ–‡å­¦åŸä½œå“å¤‡ä»½å·¥å…· v5.0                   â•‘
    â•‘                     (ä¼˜åŒ–ç‰ˆ - æ”¯æŒé€‰æ‹©å¤‡ä»½)                    â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  åŠŸèƒ½ç‰¹æ€§:                                                     â•‘
    â•‘  â€¢ ä» my_cookie.txt æ–‡ä»¶è¯»å–Cookie                            â•‘
    â•‘  â€¢ æ”¯æŒé€‰æ‹©å•æœ¬æˆ–å¤šæœ¬ä½œå“å¤‡ä»½                                  â•‘
    â•‘  â€¢ å®æ—¶ä¿å­˜ï¼Œè¾¹ä¸‹è½½è¾¹ç”ŸæˆDOCXæ–‡ä»¶                             â•‘
    â•‘  â€¢ å®Œæ•´ä¿ç•™æ­£æ–‡æ ¼å¼å’Œä½œè€…æœ‰è¯è¯´                               â•‘
    â•‘  â€¢ è‡ªåŠ¨æ·»åŠ ç« èŠ‚ç¼–å·å’Œå±‚çº§æ ‡é¢˜                                 â•‘
    â•‘                                                                â•‘
    â•‘  ä½¿ç”¨æ–¹æ³•:                                                     â•‘
    â•‘  1. å‡†å¤‡Cookie: ç™»å½•æ™‹æ±Ÿâ†’F12â†’Networkâ†’å¤åˆ¶Cookieåˆ°txtæ–‡ä»¶     â•‘
    â•‘  2. è¿è¡Œç¨‹åº: python jjwxc_col.py                            â•‘
    â•‘  3. é€‰æ‹©ä½œå“: æ ¹æ®æç¤ºé€‰æ‹©è¦å¤‡ä»½çš„ä½œå“                        â•‘
    â•‘  4. æŸ¥çœ‹ç»“æœ: å¤‡ä»½å®ŒæˆåæŸ¥çœ‹ç”Ÿæˆçš„DOCXæ–‡ä»¶                   â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # æ£€æŸ¥Cookieæ–‡ä»¶
    if not os.path.exists(COOKIE_FILE):
        print(f"âŒ æœªæ‰¾åˆ° {COOKIE_FILE} æ–‡ä»¶")
        print("\nğŸ“ Cookieè·å–æ­¥éª¤:")
        print("1. ä½¿ç”¨æµè§ˆå™¨ç™»å½•æ™‹æ±Ÿæ–‡å­¦åŸä½œè€…åå°")
        print("2. æŒ‰F12æ‰“å¼€å¼€å‘è€…å·¥å…·")
        print("3. åˆ‡æ¢åˆ°Network(ç½‘ç»œ)é€‰é¡¹å¡")
        print("4. åˆ·æ–°é¡µé¢ï¼Œç‚¹å‡»ä»»æ„è¯·æ±‚")
        print("5. åœ¨Request Headersä¸­æ‰¾åˆ°'Cookie'å­—æ®µ")
        print("6. å¤åˆ¶å®Œæ•´çš„Cookieå€¼")
        print(f"7. åˆ›å»º {COOKIE_FILE} æ–‡ä»¶ï¼Œç²˜è´´Cookieå†…å®¹å¹¶ä¿å­˜")
        print("\næŒ‰å›è½¦é”®é€€å‡º...")
        input()
        exit(1)
    
    # å¯åŠ¨å¤‡ä»½å·¥å…·
    try:
        tool = JJWXCBackupTool()
        tool.backup_all_novels()
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\nç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒCookieæ˜¯å¦æœ‰æ•ˆ")
    finally:
        print("\nç¨‹åºç»“æŸï¼ŒæŒ‰å›è½¦é”®é€€å‡º...")
        input()