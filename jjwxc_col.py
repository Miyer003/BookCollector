import os
import time
import random
import requests
from bs4 import BeautifulSoup
from docx import Document
from docx.shared import Pt, RGBColor
from docx.enum.text import WD_PARAGRAPH_ALIGNMENT
import re
import json
from datetime import datetime
import urllib.parse

COOKIE_FILE = "my_cookie.txt"

class JJWXCBackupTool:
    def __init__(self):
        # åˆ›å»ºè¾“å‡ºç›®å½•
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.output_dir = f"backup_{timestamp}"
        os.makedirs(self.output_dir, exist_ok=True)
        
        # è®¾ç½®ä¼šè¯
        self.session = requests.Session()
        self.headers = self.get_default_headers()
        
        # åˆå§‹åŒ–ä½œè€…åå°URL
        self.author_backend_url = None
        
        # åŠ è½½Cookieæ–‡ä»¶
        cookie_count = self.load_cookie()
        print(f"å·²è®¾ç½® {cookie_count} ä¸ªCookieå‚æ•°")
        
        # è®¾ç½®è¯·æ±‚é‡è¯•ç­–ç•¥
        self.session.mount('https://', requests.adapters.HTTPAdapter(
            max_retries=3,
            pool_connections=10,
            pool_maxsize=20
        ))

    def get_default_headers(self):
        """è¿”å›é»˜è®¤è¯·æ±‚å¤´"""
        return {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Connection': 'keep-alive',
            'Referer': 'https://www.jjwxc.net/',
            'Cache-Control': 'no-cache',
            'Pragma': 'no-cache'
        }
    
    def decode_unicode_escape(self, s):
        """è§£ç  %uXXXX æ ¼å¼çš„Unicodeè½¬ä¹‰åºåˆ—"""
        def replace_unicode(match):
            return chr(int(match.group(1), 16))
        return re.sub(r'%u([0-9a-fA-F]{4})', replace_unicode, s)
    
    def load_cookie(self):
        """ä»æ–‡ä»¶åŠ è½½Cookieå¹¶å¤„ç†ç‰¹æ®Šç¼–ç """
        cookie_count = 0
        if os.path.exists(COOKIE_FILE):
            try:
                with open(COOKIE_FILE, 'r', encoding='utf-8') as f:
                    # è¯»å–åŸå§‹Cookieå†…å®¹
                    raw_cookie = f.read().strip()
                    print(f"åŸå§‹Cookieå†…å®¹: {raw_cookie[:100]}...")
                    
                    # å¤„ç†Unicodeè½¬ä¹‰åºåˆ— (%uXXXX)
                    decoded_cookie = self.decode_unicode_escape(raw_cookie)
                    
                    # æ™ºèƒ½Cookieè§£æï¼šå¤„ç†åŒ…å«JSONçš„å¤æ‚Cookie
                    cookies_dict = {}
                    current_pos = 0
                    
                    while current_pos < len(decoded_cookie):
                        # æ‰¾åˆ°ä¸‹ä¸€ä¸ªç­‰å·
                        eq_pos = decoded_cookie.find('=', current_pos)
                        if eq_pos == -1:
                            break
                            
                        # æå–é”®åï¼ˆå»æ‰å‰é¢çš„åˆ†å·å’Œç©ºæ ¼ï¼‰
                        key_start = current_pos
                        if decoded_cookie[current_pos:current_pos+1] == ';':
                            key_start += 1
                        key = decoded_cookie[key_start:eq_pos].strip()
                        
                        # æ‰¾å€¼çš„éƒ¨åˆ†
                        value_start = eq_pos + 1
                        
                        # å¦‚æœå€¼ä»¥ %7B æˆ– { å¼€å¤´ï¼Œå¯èƒ½æ˜¯JSONï¼Œéœ€è¦ç‰¹æ®Šå¤„ç†
                        if (decoded_cookie[value_start:value_start+3] == '%7B' or 
                            decoded_cookie[value_start:value_start+1] == '{'):
                            # JSONå€¼ï¼šæ‰¾åˆ°åŒ¹é…çš„ç»“æŸä½ç½®
                            brace_count = 0
                            value_end = value_start
                            in_string = False
                            escape_next = False
                            
                            for i in range(value_start, len(decoded_cookie)):
                                char = decoded_cookie[i]
                                
                                if escape_next:
                                    escape_next = False
                                    continue
                                    
                                if char == '\\':
                                    escape_next = True
                                    continue
                                    
                                if char == '"' and not escape_next:
                                    in_string = not in_string
                                    continue
                                    
                                if not in_string:
                                    if char == '{' or decoded_cookie[i:i+3] == '%7B':
                                        brace_count += 1
                                        if decoded_cookie[i:i+3] == '%7B':
                                            i += 2  # è·³è¿‡ %7B çš„å…¶ä½™éƒ¨åˆ†
                                    elif char == '}' or decoded_cookie[i:i+3] == '%7D':
                                        brace_count -= 1
                                        if decoded_cookie[i:i+3] == '%7D':
                                            i += 2
                                        if brace_count == 0:
                                            value_end = i + 1
                                            break
                                    elif char == ';' and brace_count == 0:
                                        value_end = i
                                        break
                                        
                                value_end = i + 1
                        else:
                            # æ™®é€šå€¼ï¼šæ‰¾åˆ°ä¸‹ä¸€ä¸ªåˆ†å·æˆ–å­—ç¬¦ä¸²ç»“å°¾
                            value_end = decoded_cookie.find(';', value_start)
                            if value_end == -1:
                                value_end = len(decoded_cookie)
                        
                        # æå–å€¼
                        value = decoded_cookie[value_start:value_end].strip()
                        
                        # å¤„ç†å€¼çš„URLè§£ç 
                        if key and value:
                            try:
                                # å¯¹äºJSONæ ¼å¼çš„Cookieå€¼ï¼Œè°¨æ…å¤„ç†URLè§£ç 
                                if value.startswith('%7B') or value.startswith('{'):
                                    # å°è¯•è§£ç ï¼Œä½†å¦‚æœå¤±è´¥å°±ä¿æŒåŸæ ·
                                    try:
                                        decoded_value = urllib.parse.unquote(value)
                                        # éªŒè¯è§£ç åçš„JSONæ˜¯å¦æœ‰æ•ˆ
                                        if decoded_value.startswith('{') and decoded_value.endswith('}'):
                                            json.loads(decoded_value)  # éªŒè¯JSONæ ¼å¼
                                    except:
                                        decoded_value = value  # è§£ç å¤±è´¥ï¼Œä¿æŒåŸæ ·
                                else:
                                    # æ™®é€šå€¼ï¼Œç›´æ¥è§£ç 
                                    decoded_value = urllib.parse.unquote(value)
                                
                                cookies_dict[key] = decoded_value
                                self.session.cookies.set(key, decoded_value)
                                print(f"  â†’ è®¾ç½®Cookie: {key}={decoded_value[:50]}...")
                                cookie_count += 1
                                
                            except Exception as decode_error:
                                print(f"  Ã— è·³è¿‡æ— æ•ˆCookie: {key} (è§£ç é”™è¯¯: {decode_error})")
                        
                        # ç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªCookie
                        current_pos = value_end
                        if current_pos < len(decoded_cookie) and decoded_cookie[current_pos] == ';':
                            current_pos += 1
                    
                    print(f"æˆåŠŸè§£æ {cookie_count} ä¸ªCookie")
                    return cookie_count
                    
            except Exception as e:
                print(f"Cookieæ–‡ä»¶è§£æé”™è¯¯: {e}")
        
        return 0
    
    def check_login(self):
        """æ£€æŸ¥ç™»å½•çŠ¶æ€"""
        self.author_backend_url = "https://my.jjwxc.net/backend/oneauthor_login.php"
        try:
            print("æ­£åœ¨æ£€æŸ¥ç™»å½•çŠ¶æ€...")
            response = self.session.get(self.author_backend_url, headers=self.headers, timeout=15)
            response.encoding = 'gb18030'
            html = response.text

            # åˆ¤æ–­é¡µé¢æ˜¯å¦åŒ…å«ç™»å½•æç¤º
            if "æ™‹æ±Ÿæ–‡å­¦åŸ" in html:
                print("ç™»å…¥æˆåŠŸ")
                return True
            elif "è¯·ç™»å½•" in html or "ç™»å½•æ™‹æ±Ÿä½œè€…åå°" in html or "è´¦å·" in html:
                print("æœªç™»å½•æ™‹æ±Ÿä½œè€…åå°ï¼Œè¯·æ£€æŸ¥Cookieæ˜¯å¦æœ‰æ•ˆ")
                return False
        except Exception as e:
            print(f"æ£€æŸ¥ç™»å½•çŠ¶æ€æ—¶å‡ºé”™: {e}")
            return False
        
    def get_novel_list(self):
        """è·å–ä½œè€…ä½œå“åˆ—è¡¨"""
        author_url = "https://my.jjwxc.net/backend/oneauthor_login.php"
        
        try:
            print(f"è·å–ä½œå“åˆ—è¡¨: {author_url}")
            response = self.session.get(author_url, headers=self.headers, timeout=20)
            
            # è®¾ç½®æ­£ç¡®çš„ç¼–ç 
            response.encoding = 'gb18030'  # æ™‹æ±Ÿä½¿ç”¨gb18030ç¼–ç 
            
            soup = BeautifulSoup(response.content, 'html.parser', from_encoding='gb18030')
            novels = []
            
            # ä¿å­˜é¡µé¢ç”¨äºè°ƒè¯•
            with open(os.path.join(self.output_dir, "novel_list.html"), "w", encoding="utf-8") as f:
                f.write(response.text)
            print("ä½œå“åˆ—è¡¨é¡µé¢å·²ä¿å­˜: novel_list.html")
            
            # æŸ¥æ‰¾ä½œå“ç®¡ç†é“¾æ¥
            # åœ¨æ™‹æ±Ÿåå°ï¼Œä½œå“ç®¡ç†é“¾æ¥çš„æ ¼å¼æ˜¯: managenovel.php?novelid=XXXXX
            novel_links = soup.find_all('a', href=lambda x: x and 'managenovel.php?novelid=' in x)
            
            if novel_links:
                print(f"æ‰¾åˆ° {len(novel_links)} ä¸ªä½œå“ç®¡ç†é“¾æ¥")
                
                for link in novel_links:
                    # æå–ä½œå“ID
                    href = link['href']
                    novel_id_match = re.search(r'novelid=(\d+)', href)
                    if novel_id_match:
                        novel_id = novel_id_match.group(1)
                        
                        # æŸ¥æ‰¾ä½œå“æ ‡é¢˜ï¼ˆåœ¨åŒä¸€è¡Œçš„å…¶ä»–ä½ç½®ï¼‰
                        row = link.find_parent('tr')
                        if row:
                            # æŸ¥æ‰¾ä½œå“æ ‡é¢˜é“¾æ¥ï¼ˆæŒ‡å‘onebook.phpçš„é“¾æ¥ï¼‰
                            title_link = row.find('a', href=lambda x: x and f'onebook.php?novelid={novel_id}' in x)
                            if title_link:
                                title = title_link.get_text(strip=True)
                                
                        # æå–å…¶ä»–ä¿¡æ¯
                        cells = row.find_all('td')
                        if len(cells) >= 10:
                            try:
                                # æ ¹æ®HTMLç»“æ„æå–ä¿¡æ¯
                                category = cells[2].get_text(strip=True) if len(cells) > 2 else "æœªçŸ¥"
                                subcategory = cells[3].get_text(strip=True) if len(cells) > 3 else "æœªçŸ¥"
                                chapter_count = cells[5].get_text(strip=True) if len(cells) > 5 else "0"
                                word_count = cells[6].get_text(strip=True) if len(cells) > 6 else "0"
                                status = cells[12].get_text(strip=True) if len(cells) > 12 else "æœªçŸ¥"
                                
                                novels.append({
                                    'id': novel_id,
                                    'title': title,
                                    'link': href,
                                    'view_link': title_link['href'],
                                    'status': status,
                                    'word_count': word_count,
                                    'chapter_count': chapter_count,
                                    'category': f"{category}-{subcategory}"
                                })
                                
                            except Exception as e:
                                print(f"è§£æä½œå“ä¿¡æ¯å‡ºé”™ {novel_id}: {e}")
                                novels.append({
                                    'id': novel_id,
                                    'title': title,
                                    'link': href,
                                    'view_link': title_link['href'],
                                    'status': "æœªçŸ¥",
                                    'word_count': "æœªçŸ¥",
                                    'chapter_count': "æœªçŸ¥",
                                    'category': "æœªçŸ¥"
                                })
                
                print(f"æˆåŠŸè§£æ {len(novels)} éƒ¨ä½œå“")
                return novels
            else:
                print("æœªæ‰¾åˆ°ä½œå“ç®¡ç†é“¾æ¥")
                # å¤‡ç”¨æ–¹æ³•ï¼šæŸ¥æ‰¾onebook.phpé“¾æ¥
                onebook_links = soup.find_all('a', href=lambda x: x and 'onebook.php?novelid=' in x)
                if onebook_links:
                    print(f"æ‰¾åˆ° {len(onebook_links)} ä¸ªä½œå“é˜…è¯»é“¾æ¥")
                    for idx, link in enumerate(onebook_links):
                        href = link['href']
                        novel_id_match = re.search(r'novelid=(\d+)', href)
                        if novel_id_match:
                            novel_id = novel_id_match.group(1)
                            title = link.get_text(strip=True)
                            
                            novels.append({
                                'id': novel_id,
                                'title': title,
                                'link': f"//my.jjwxc.net/backend/managenovel.php?novelid={novel_id}",
                                'view_link': href,
                                'status': "æœªçŸ¥",
                                'word_count': "æœªçŸ¥",
                                'chapter_count': "æœªçŸ¥",
                                'category': "æœªçŸ¥"
                            })
                    
                    return novels
                else:
                    print("ä¹Ÿæœªæ‰¾åˆ°ä½œå“é˜…è¯»é“¾æ¥")
                    return []
            
        except Exception as e:
            print(f"è·å–ä½œå“åˆ—è¡¨å‡ºé”™: {str(e)}")
            return []
    
    def get_intro_from_backend(self, novel_id):
        """ä»ä½œè€…åå°è·å–ä½œå“ç®€ä»‹"""
        try:
            backend_url = f"https://my.jjwxc.net/backend/managenovel.php?novelid={novel_id}"
            print(f"è®¿é—®åå°ç« èŠ‚ç®¡ç†é¡µé¢: {backend_url}")
            headers = self.headers.copy()
            headers['Referer'] = 'https://my.jjwxc.net/backend/'
            response = self.session.get(backend_url, headers=headers, timeout=30)
            response.encoding = 'gb18030'
            soup = BeautifulSoup(response.content, 'html.parser', from_encoding='gb18030')
            novel_intro = ""
            intro_textarea = soup.find('textarea', {'id': 'novelintro'})
            if intro_textarea:
                novel_intro = intro_textarea.get_text(strip=True)
                print(f"è·å–åˆ°ä½œå“ç®€ä»‹: {len(novel_intro)} å­—ç¬¦")
            return novel_intro
        except Exception as e:
            print(f"è·å–ä½œå“ç®€ä»‹å¤±è´¥: {e}")
            return ""

    def get_chapters(self, novel_link):
        """è·å–ä½œå“ç« èŠ‚åˆ—è¡¨"""
        if not novel_link:
            return []
            
        try:
            # æå–novelid
            novel_id_match = re.search(r'novelid=(\d+)', novel_link)
            if not novel_id_match:
                print(f"æ— æ³•ä»é“¾æ¥ä¸­æå–ä½œå“ID: {novel_link}")
                return []
            novel_id = novel_id_match.group(1)
            backend_url = f"https://my.jjwxc.net/backend/managenovel.php?novelid={novel_id}"
            print(f"è·å–æ‰€æœ‰ç« èŠ‚åˆ—è¡¨: {backend_url}")
            response = self.session.get(backend_url, headers=self.headers, timeout=30)
            response.encoding = 'gb18030'
            soup = BeautifulSoup(response.content, 'html.parser', from_encoding='gb18030')
            chapters = []
            # æ™‹æ±Ÿåå°ç« èŠ‚ç®¡ç†é¡µé¢é€šå¸¸æœ‰ç« èŠ‚åˆ—è¡¨table
            # è§£ææ‰€æœ‰trï¼ˆæ¯ä¸€ç« ï¼‰
            for idx, tr in enumerate(soup.find_all('tr')):
                chapter_id_tag = tr.find('input', {'name': 'chapterid'})
                title_tag = tr.find('a', href=True)
                if chapter_id_tag and title_tag:
                    chapter_id = chapter_id_tag['value']
                    title = title_tag.get_text(strip=True)
                    # åˆ¤æ–­æ˜¯å¦VIPç« èŠ‚
                    is_vip = False
                    # é€šå¸¸VIPç« èŠ‚ä¼šæœ‰VIPæ ‡è¯†ï¼ˆå¦‚classã€spanã€imgç­‰ï¼‰
                    vip_tag = tr.find('span', class_=lambda x: x and 'vip' in x.lower())
                    if vip_tag or 'VIP' in title or 'vip' in title.lower():
                        is_vip = True
                    # æ‹¼æ¥è®¿é—®é“¾æ¥
                    if is_vip:
                        link = f"https://my.jjwxc.net/onebook_vip.php?novelid={novel_id}&chapterid={chapter_id}"
                    else:
                        link = f"https://www.jjwxc.net/onebook.php?novelid={novel_id}&chapterid={chapter_id}"
                    chapters.append({
                        'id': chapter_id,
                        'title': title,
                        'link': link,
                        'chapter_number': idx + 1,
                        'is_vip': is_vip
                    })
            vip_count = sum(1 for c in chapters if c['is_vip'])
            free_count = len(chapters) - vip_count
            print(f"æˆåŠŸè§£æ {len(chapters)} ä¸ªç« èŠ‚ï¼Œå…¶ä¸­å…è´¹ç« èŠ‚æ•°é‡ï¼š{free_count}ï¼ŒVIPç« èŠ‚æ•°é‡ï¼š{vip_count}")
            return chapters
        except Exception as e:
            print(f"è·å–ç« èŠ‚åˆ—è¡¨å‡ºé”™: {str(e)}")
            return []
    
    def get_chapter_content(self, chapter_link, is_vip=False):
        """è·å–ç« èŠ‚å†…å®¹ï¼ˆåŒºåˆ†å…è´¹å’ŒVIPç« èŠ‚ï¼‰"""
        if not chapter_link:
            return "ç« èŠ‚é“¾æ¥æ— æ•ˆ"
        try:
            # å…è´¹ç« èŠ‚å¤„ç†é€»è¾‘
            if not is_vip:
                if not chapter_link.startswith('http'):
                    chapter_link = f"https://www.jjwxc.net{chapter_link}"
                print(f"  è·å–å…è´¹ç« èŠ‚å†…å®¹...")
                response = self.session.get(chapter_link, headers=self.headers, timeout=30)
                response.encoding = 'gb18030'
                soup = BeautifulSoup(response.content, 'html.parser', from_encoding='gb18030')
                main_content = ""
                novelbody_div = soup.find('div', class_='novelbody')
                if novelbody_div:
                    text_container = novelbody_div.select_one('div > div')
                    if text_container:
                        content_parts = []
                        for element in text_container.children:
                            if getattr(element, 'name', None) == 'br':
                                content_parts.append('\n')
                            elif getattr(element, 'string', None) and element.string.strip():
                                content_parts.append(element.string.strip())
                        main_content = ''.join(content_parts)
                author_notes = ""
                note_wrapper = soup.find('div', id='note_danmu_wrapper')
                if note_wrapper:
                    note_str = note_wrapper.find('div', id='note_str')
                    if note_str:
                        html_content = str(note_str)
                        html_content = re.sub(r'<br\s*/?>', '\n', html_content, flags=re.IGNORECASE)
                        clean_soup = BeautifulSoup(html_content, 'html.parser')
                        author_notes = clean_soup.get_text(strip=True)
                result_parts = []
                if main_content and len(main_content) > 20:
                    result_parts.append(main_content)
                if author_notes and len(author_notes) > 10:
                    result_parts.append('\n\nã€ä½œè€…æœ‰è¯è¯´ã€‘')
                    result_parts.append(author_notes)
                if result_parts:
                    result = ''.join(result_parts)
                    if len(result.strip()) > 30:
                        return result
                return "å†…å®¹è·å–å¤±è´¥ï¼šæœªæ‰¾åˆ°æœ‰æ•ˆå†…å®¹"
            # VIPç« èŠ‚å¤„ç†é€»è¾‘ï¼ˆé¢„ç•™ç»“æ„ï¼Œå¾…å¡«å†™ï¼‰
            else:
                if not chapter_link.startswith('http'):
                    chapter_link = f"https://my.jjwxc.net{chapter_link}"
                print(f"  è·å–VIPç« èŠ‚å†…å®¹...")
                response = self.session.get(chapter_link, headers=self.headers, timeout=30)
                response.encoding = 'gb18030'
                soup = BeautifulSoup(response.content, 'html.parser', from_encoding='gb18030')
                main_content = ""
                # æå–VIPæ­£æ–‡å†…å®¹
                novelbody_div = soup.find('div', class_='novelbody')
                if novelbody_div:
                    noveltext_div = novelbody_div.find('div', class_=lambda x: x and x.startswith('noveltext'))
                    if noveltext_div:
                        content_div = noveltext_div.find('div', id=lambda x: x and x.startswith('content_'))
                        if content_div:
                            content_parts = []
                            for element in content_div.children:
                                if getattr(element, 'name', None) == 'br':
                                    content_parts.append('\n')
                                elif getattr(element, 'string', None) and element.string.strip():
                                    content_parts.append(element.string.strip())
                            main_content = ''.join(content_parts)
                author_notes = ""
                # æå–VIPä½œè€…æœ‰è¯è¯´
                if novelbody_div:
                    noveltext_div = novelbody_div.find('div', class_=lambda x: x and x.startswith('noveltext'))
                    if noveltext_div:
                        note_wrapper = noveltext_div.find('div', id='note_danmu_wrapper')
                        if note_wrapper:
                            note_main = note_wrapper.find('div', id='note_main')
                            if note_main:
                                html_content = str(note_main)
                                html_content = re.sub(r'<br\s*/?>', '\n', html_content, flags=re.IGNORECASE)
                                clean_soup = BeautifulSoup(html_content, 'html.parser')
                                author_notes = clean_soup.get_text(strip=True)
                result_parts = []
                if main_content and len(main_content) > 20:
                    result_parts.append(main_content)
                if author_notes and len(author_notes) > 10:
                    result_parts.append('\n\nã€ä½œè€…æœ‰è¯è¯´ã€‘')
                    result_parts.append(author_notes)
                if result_parts:
                    result = ''.join(result_parts)
                    if len(result.strip()) > 30:
                        return result
                return "å†…å®¹è·å–å¤±è´¥ï¼šæœªæ‰¾åˆ°æœ‰æ•ˆå†…å®¹"
        except Exception as e:
            print(f"  ç« èŠ‚å†…å®¹è·å–å‡ºé”™: {str(e)}")
            return f"å†…å®¹è·å–å¤±è´¥ï¼š{str(e)}"

    def create_docx_with_realtime_save(self, novel, chapters):
        """åˆ›å»ºDOCXæ–‡æ¡£å¹¶å®æ—¶ä¿å­˜ç« èŠ‚å†…å®¹"""
        if not chapters:
            print(f"æ²¡æœ‰æ‰¾åˆ°ç« èŠ‚å†…å®¹ï¼Œè·³è¿‡ {novel['title']}")
            return
        
        try:
            # åˆ›å»ºWordæ–‡æ¡£
            doc = Document()
            
            # æ·»åŠ ä½œå“æ ‡é¢˜ï¼ˆæœ€é«˜çº§æ ‡é¢˜ï¼‰
            title_paragraph = doc.add_heading(novel['title'], level=0)
            title_paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
            
            # æ·»åŠ ä½œå“åŸºæœ¬ä¿¡æ¯
            info_paragraph = doc.add_paragraph()
            info_paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
            
            info_run = info_paragraph.add_run(
                f"ä½œå“ID: {novel['id']} | "
                f"å­—æ•°: {novel.get('word_count', 'æœªçŸ¥')} | "
                f"çŠ¶æ€: {novel.get('status', 'æœªçŸ¥')}"
            )
            info_run.font.size = Pt(10)
            
            # è·å–ä½œå“ç®€ä»‹å¹¶æ’å…¥åˆ°çŠ¶æ€ä¸‹æ–¹
            novel_intro = self.get_intro_from_backend(novel['id'])
            if novel_intro:
                intro_paragraph = doc.add_paragraph(novel_intro)
                intro_paragraph.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
                intro_paragraph.runs[0].font.size = Pt(11)
            
            # æ·»åŠ åˆ†é¡µç¬¦
            doc.add_page_break()
            
            # å‡†å¤‡æ–‡ä»¶åå’Œè·¯å¾„
            filename = self._clean_filename(novel['title'])
            filepath = os.path.join(self.output_dir, f"{filename}.docx")
            
            total_chapters = len(chapters)
            print(f"å¼€å§‹å¤„ç†: {novel['title']} ({total_chapters}ç« )")
            print(f"æ–‡æ¡£å°†ä¿å­˜ä¸º: {filepath}")
            
            # å…ˆä¿å­˜åˆå§‹æ–‡æ¡£ç»“æ„
            doc.save(filepath)
            print(f"âœ“ å·²åˆ›å»ºåˆå§‹æ–‡æ¡£ï¼Œå¯ä»¥æ‰“å¼€æŸ¥çœ‹")
            
            # é€ç« èŠ‚å¤„ç†å¹¶å®æ—¶ä¿å­˜
            for idx, chapter in enumerate(chapters):
                try:
                    # æ·»åŠ ç« èŠ‚æ ‡é¢˜ï¼ˆå¸¦ç« èŠ‚ç¼–å·ï¼‰
                    chapter_title = f"ç¬¬{chapter.get('chapter_number', idx+1)}ç«  {chapter['title']}"
                    doc.add_heading(chapter_title, level=1)
                    
                    # è·å–ç« èŠ‚å†…å®¹
                    print(f"æ­£åœ¨è·å–: {chapter_title} [{idx+1}/{total_chapters}]")
                    content = self.get_chapter_content(chapter['link'])
                    
                    # æ£€æŸ¥å†…å®¹æ˜¯å¦æœ‰æ•ˆ
                    if content and not content.startswith("å†…å®¹è·å–å¤±è´¥") and not content.startswith("ç« èŠ‚é“¾æ¥æ— æ•ˆ"):
                        self._add_content_to_doc(doc, content)
                    else:
                        # å†…å®¹è·å–å¤±è´¥çš„æƒ…å†µ
                        error_paragraph = doc.add_paragraph(f"[ç« èŠ‚å†…å®¹è·å–å¤±è´¥: {content}]")
                        error_paragraph.runs[0].font.color.rgb = RGBColor(255, 0, 0)
                    
                    # æ·»åŠ ç« èŠ‚åˆ†éš”ç¬¦
                    if idx < total_chapters - 1:
                        doc.add_paragraph()
                        separator = doc.add_paragraph("â”€" * 50)
                        separator.alignment = WD_PARAGRAPH_ALIGNMENT.CENTER
                        doc.add_paragraph()
                    
                    # å®æ—¶ä¿å­˜æ–‡æ¡£
                    doc.save(filepath)
                    print(f"âœ“ å·²ä¿å­˜ [{idx+1}/{total_chapters}]")
                    
                except Exception as e:
                    print(f"å¤„ç†ç« èŠ‚å‡ºé”™: {str(e)}")
                    error_paragraph = doc.add_paragraph(f"[ç« èŠ‚å¤„ç†é”™è¯¯: {chapter['title']} - {str(e)}]")
                    error_paragraph.runs[0].font.color.rgb = RGBColor(255, 0, 0)
                    doc.save(filepath)
                
                # å»¶è¿Ÿé¿å…è¯·æ±‚è¿‡å¿«
                time.sleep(random.uniform(1.0, 2.0))
            
            print(f"âœ“ å®Œæˆä¿å­˜: {novel['title']}")
            
        except Exception as e:
            print(f"åˆ›å»ºæ–‡æ¡£å‡ºé”™: {str(e)}")
    
    def _clean_filename(self, filename):
        """æ¸…ç†æ–‡ä»¶åä¸­çš„éæ³•å­—ç¬¦"""
        invalid_chars = '<>:"/\\|?*'
        for char in invalid_chars:
            filename = filename.replace(char, '_')
        
        if not filename.strip() or filename.strip() == '_':
            filename = f"novel_{int(time.time())}"
        
        return filename
    
    def _add_content_to_doc(self, doc, content):
        """å°†å†…å®¹æ·»åŠ åˆ°æ–‡æ¡£ä¸­"""
        # åˆ†ç¦»æ­£æ–‡å’Œä½œè€…æœ‰è¯è¯´
        main_text = ""
        author_notes = ""
        
        if 'ã€ä½œè€…æœ‰è¯è¯´ã€‘' in content:
            parts = content.split('ã€ä½œè€…æœ‰è¯è¯´ã€‘', 1)
            main_text = parts[0].strip()
            if len(parts) > 1:
                author_notes = parts[1].strip()
        else:
            main_text = content.strip()
        
        # æ·»åŠ æ­£æ–‡å†…å®¹
        if main_text:
            paragraphs = main_text.split('\n\n')
            for para in paragraphs:
                if para.strip():
                    lines = para.split('\n')
                    if len(lines) == 1:
                        doc.add_paragraph(lines[0].strip())
                    else:
                        paragraph = doc.add_paragraph()
                        for line_idx, line in enumerate(lines):
                            line = line.strip()
                            if line:
                                if line_idx > 0:
                                    paragraph.add_run().add_break()
                                paragraph.add_run(line)
        
        # æ·»åŠ ä½œè€…æœ‰è¯è¯´éƒ¨åˆ†
        if author_notes:
            author_heading = doc.add_heading('ä½œè€…æœ‰è¯è¯´', level=2)
            author_heading.runs[0].font.color.rgb = RGBColor(0, 0, 255)
            
            note_paragraphs = author_notes.split('\n\n')
            for note_para in note_paragraphs:
                if note_para.strip():
                    lines = note_para.split('\n')
                    if len(lines) == 1:
                        doc.add_paragraph(lines[0].strip())
                    else:
                        paragraph = doc.add_paragraph()
                        for line_idx, line in enumerate(lines):
                            line = line.strip()
                            if line:
                                if line_idx > 0:
                                    paragraph.add_run().add_break()
                                paragraph.add_run(line)
    
    def select_novels_to_backup(self, novels):
        """ç”¨æˆ·é€‰æ‹©è¦å¤‡ä»½çš„ä½œå“"""
        if not novels:
            return []
        
        print("\n" + "="*50)
        print("å‘ç°ä»¥ä¸‹ä½œå“ï¼š")
        print("="*50)
        
        for idx, novel in enumerate(novels):
            print(f"{idx+1:2d}. {novel['title']}")
            print(f"     ID: {novel['id']} | å­—æ•°: {novel.get('word_count', 'æœªçŸ¥')} | çŠ¶æ€: {novel.get('status', 'æœªçŸ¥')}")
        
        print("\né€‰æ‹©æ–¹å¼ï¼š")
        print("  è¾“å…¥æ•°å­—é€‰æ‹©å•æœ¬ä½œå“ï¼ˆå¦‚ï¼š1ï¼‰")
        print("  è¾“å…¥å¤šä¸ªæ•°å­—é€‰æ‹©å¤šæœ¬ä½œå“ï¼ˆå¦‚ï¼š1,3,5ï¼‰")
        print("  è¾“å…¥ 'all' æˆ– 'a' å¤‡ä»½å…¨éƒ¨ä½œå“")
        print("  è¾“å…¥ 'quit' æˆ– 'q' é€€å‡ºç¨‹åº")
        
        while True:
            try:
                choice = input("\nè¯·è¾“å…¥é€‰æ‹©: ").strip().lower()
                
                if choice in ['quit', 'q']:
                    print("é€€å‡ºç¨‹åº")
                    return []
                
                if choice in ['all', 'a']:
                    print(f"é€‰æ‹©å¤‡ä»½å…¨éƒ¨ {len(novels)} éƒ¨ä½œå“")
                    return novels
                
                # è§£ææ•°å­—é€‰æ‹©
                selected_indices = []
                for item in choice.split(','):
                    item = item.strip()
                    if item.isdigit():
                        idx = int(item) - 1
                        if 0 <= idx < len(novels):
                            selected_indices.append(idx)
                        else:
                            print(f"æ•°å­— {item} è¶…å‡ºèŒƒå›´ï¼Œè¯·é‡æ–°è¾“å…¥")
                            break
                    else:
                        print(f"æ— æ•ˆè¾“å…¥ '{item}'ï¼Œè¯·é‡æ–°è¾“å…¥")
                        break
                else:
                    if selected_indices:
                        selected_novels = [novels[i] for i in selected_indices]
                        print(f"é€‰æ‹©å¤‡ä»½ {len(selected_novels)} éƒ¨ä½œå“:")
                        for novel in selected_novels:
                            print(f"  - {novel['title']}")
                        return selected_novels
                    else:
                        print("æœªé€‰æ‹©ä»»ä½•ä½œå“ï¼Œè¯·é‡æ–°è¾“å…¥")
                        
            except KeyboardInterrupt:
                print("\n\nç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç¨‹åº")
                return []
            except Exception as e:
                print(f"è¾“å…¥é”™è¯¯: {e}ï¼Œè¯·é‡æ–°è¾“å…¥")
    
    def backup_all_novels(self):
        """å¤‡ä»½ä½œå“ä¸»æµç¨‹"""
        print("æ­£åœ¨åˆå§‹åŒ–...")
        
        # æ£€æŸ¥ç™»å½•çŠ¶æ€
        self.check_login()
        
        # è·å–ä½œå“åˆ—è¡¨
        print("æ­£åœ¨è·å–ä½œå“åˆ—è¡¨...")
        novels = self.get_novel_list()
        
        if not novels:
            print("âŒ æ²¡æœ‰æ‰¾åˆ°ä½œå“")
            return
        
        print(f"âœ“ æˆåŠŸè·å– {len(novels)} éƒ¨ä½œå“")
        
        # ç”¨æˆ·é€‰æ‹©è¦å¤‡ä»½çš„ä½œå“
        selected_novels = self.select_novels_to_backup(novels)
        if not selected_novels:
            return
        
        # ä¿å­˜ä½œå“åˆ—è¡¨ä¿¡æ¯
        with open(os.path.join(self.output_dir, "ä½œå“åˆ—è¡¨.json"), "w", encoding="utf-8") as f:
            json.dump(selected_novels, f, ensure_ascii=False, indent=2)
        
        total_novels = len(selected_novels)
        print(f"\n{'='*50}")
        print(f"å¼€å§‹å¤‡ä»½ {total_novels} éƒ¨ä½œå“")
        print(f"{'='*50}")
        
        # å¤‡ä»½æ¯éƒ¨ä½œå“
        for idx, novel in enumerate(selected_novels):
            print(f"\nâ–¶ [{idx+1}/{total_novels}] å¼€å§‹å¤‡ä»½: {novel['title']}")
            
            # è·å–ç« èŠ‚åˆ—è¡¨
            chapters = self.get_chapters(novel['link'])
            
            if chapters:
                # åˆ›å»ºDOCXæ–‡ä»¶
                self.create_docx_with_realtime_save(novel, chapters)
            else:
                print(f"âŒ æœªæ‰¾åˆ°ç« èŠ‚ï¼Œè·³è¿‡: {novel['title']}")
            
            # ä½œå“é—´å»¶è¿Ÿ
            if idx < total_novels - 1:
                delay = random.uniform(2.0, 4.0)
                print(f"ç­‰å¾… {delay:.1f} ç§’åç»§ç»­...")
                time.sleep(delay)
        
        print(f"\n{'='*50}")
        print(f"ğŸ‰ å¤‡ä»½å®Œæˆï¼æ–‡ä»¶å·²ä¿å­˜åˆ°: {self.output_dir}")
        print(f"{'='*50}")


if __name__ == "__main__":
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘                  æ™‹æ±Ÿæ–‡å­¦åŸä½œå“å¤‡ä»½å·¥å…· v5.0                   â•‘
    â•‘                     (ä¼˜åŒ–ç‰ˆ - æ”¯æŒé€‰æ‹©å¤‡ä»½)                    â•‘
    â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
    â•‘  åŠŸèƒ½ç‰¹æ€§:                                                     â•‘
    â•‘  â€¢ ä» my_cookie.txt æ–‡ä»¶è¯»å–Cookie                            â•‘
    â•‘  â€¢ æ”¯æŒé€‰æ‹©å•æœ¬æˆ–å¤šæœ¬ä½œå“å¤‡ä»½                                  â•‘
    â•‘  â€¢ å®æ—¶ä¿å­˜ï¼Œè¾¹ä¸‹è½½è¾¹ç”ŸæˆDOCXæ–‡ä»¶                             â•‘
    â•‘  â€¢ å®Œæ•´ä¿ç•™æ­£æ–‡æ ¼å¼å’Œä½œè€…æœ‰è¯è¯´                               â•‘
    â•‘  â€¢ è‡ªåŠ¨æ·»åŠ ç« èŠ‚ç¼–å·å’Œå±‚çº§æ ‡é¢˜                                 â•‘
    â•‘                                                                â•‘
    â•‘  ä½¿ç”¨æ–¹æ³•:                                                     â•‘
    â•‘  1. å‡†å¤‡Cookie: ç™»å½•æ™‹æ±Ÿâ†’F12â†’Networkâ†’å¤åˆ¶Cookieåˆ°txtæ–‡ä»¶     â•‘
    â•‘  2. è¿è¡Œç¨‹åº: python jjwxc_col.py                            â•‘
    â•‘  3. é€‰æ‹©ä½œå“: æ ¹æ®æç¤ºé€‰æ‹©è¦å¤‡ä»½çš„ä½œå“                        â•‘
    â•‘  4. æŸ¥çœ‹ç»“æœ: å¤‡ä»½å®ŒæˆåæŸ¥çœ‹ç”Ÿæˆçš„DOCXæ–‡ä»¶                   â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # æ£€æŸ¥Cookieæ–‡ä»¶
    if not os.path.exists(COOKIE_FILE):
        print(f"âŒ æœªæ‰¾åˆ° {COOKIE_FILE} æ–‡ä»¶")
        print("\nğŸ“ Cookieè·å–æ­¥éª¤:")
        print("1. ä½¿ç”¨æµè§ˆå™¨ç™»å½•æ™‹æ±Ÿæ–‡å­¦åŸä½œè€…åå°")
        print("2. æŒ‰F12æ‰“å¼€å¼€å‘è€…å·¥å…·")
        print("3. åˆ‡æ¢åˆ°Network(ç½‘ç»œ)é€‰é¡¹å¡")
        print("4. åˆ·æ–°é¡µé¢ï¼Œç‚¹å‡»ä»»æ„è¯·æ±‚")
        print("5. åœ¨Request Headersä¸­æ‰¾åˆ°'Cookie'å­—æ®µ")
        print("6. å¤åˆ¶å®Œæ•´çš„Cookieå€¼")
        print(f"7. åˆ›å»º {COOKIE_FILE} æ–‡ä»¶ï¼Œç²˜è´´Cookieå†…å®¹å¹¶ä¿å­˜")
        print("\næŒ‰å›è½¦é”®é€€å‡º...")
        input()
        exit(1)
    
    # å¯åŠ¨å¤‡ä»½å·¥å…·
    try:
        tool = JJWXCBackupTool()
        tool.backup_all_novels()
    except KeyboardInterrupt:
        print("\n\nç”¨æˆ·ä¸­æ–­ç¨‹åº")
    except Exception as e:
        print(f"\nç¨‹åºè¿è¡Œå‡ºé”™: {e}")
        print("è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒCookieæ˜¯å¦æœ‰æ•ˆ")
    finally:
        print("\nç¨‹åºç»“æŸï¼ŒæŒ‰å›è½¦é”®é€€å‡º...")
        input()